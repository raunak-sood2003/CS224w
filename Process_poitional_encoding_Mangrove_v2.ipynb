{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raunak-sood2003/CS224w/blob/main/Process_poitional_encoding_Mangrove_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x40tEdIzvkT9"
      },
      "source": [
        "###Mount the drive and set the directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ByWaKmEvMo3",
        "outputId": "1bb51a57-042d-4037-f8e1-31be8507b97a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuO4rAFoviU6",
        "outputId": "c5111c06-1859-4c8c-baa7-e0a7c1bb6540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/CS224W ML on Graphs/2025/Project/Mangrove-data\n",
            "/content/drive/My Drive/CS224W ML on Graphs/2025/Project/Mangrove-data\n"
          ]
        }
      ],
      "source": [
        "# TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
        "# assignment folder, e.g. 'cs231n/assignments/assignment2/'\n",
        "FOLDERNAME = 'CS224W ML on Graphs/2025/Project/Mangrove-data/'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# Now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "# Change directory to current path\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME/\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcMyO0aXv0_c"
      },
      "source": [
        "### Download the original pkl data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42fyJTlhyN1I",
        "outputId": "697ee1f7-d2fc-4f59-8f9a-e3a1d44e2892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n"
          ]
        }
      ],
      "source": [
        "# we're going to be using Pytorch, the most widely used framework for ML research right now.\n",
        "# Pytorch is already installed so all we have to worry about is that everything else we do is compatible with our version of Pytorch\n",
        "import torch\n",
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOCdRl82yRCe",
        "outputId": "343859df-13d6-48d1-9a91-351c2cb7e575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.9.0+cu126.html\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-cluster\n",
            "  Downloading torch_cluster-1.6.3.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torch-sparse, torch-scatter, torch-cluster\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp312-cp312-linux_x86_64.whl size=3039805 sha256=42e47caff3ba8a87ef6bbed8fc1bf23322d7e8fc44bd6fdf2bb64574065c0b4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/fa/21/bd1d78ce1629aec4ecc924a63b82f6949dda484b6321eac6f2\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp312-cp312-linux_x86_64.whl size=3857028 sha256=870c2ea64fc9b512b233f467a4be57d3bc0830d8731181902e8885c3c68a8964\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/20/50/44800723f57cd798630e77b3ec83bc80bd26a1e3dc3a672ef5\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.6.3-cp312-cp312-linux_x86_64.whl size=2205973 sha256=cf54f3948ba47339dfe0afde6093c75c9a2b2f14c1ef97f79b674222a7a80346\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/8f/d0/13408a84825c9a587151a74727b4a6d47ec67e0d625b385ad7\n",
            "Successfully built torch-sparse torch-scatter torch-cluster\n",
            "Installing collected packages: torch-scatter, torch-sparse, torch-cluster, torch-geometric\n",
            "Successfully installed torch-cluster-1.6.3 torch-geometric-2.7.0 torch-scatter-2.1.2 torch-sparse-0.6.18\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "#here we load the libraries needed for doing ML on graphs, pytorch geometric, and a little package that can help with making our training faster\n",
        "!pip install torch-geometric \\\n",
        "  torch-sparse \\\n",
        "  torch-scatter \\\n",
        "  torch-cluster \\\n",
        "  -f https://pytorch-geometric.com/whl/torch-${TORCH}.html\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGVhg1WQwrwM"
      },
      "outputs": [],
      "source": [
        "import pickle, time, os\n",
        "import numpy as np\n",
        "import os.path as osp\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import string\n",
        "from tqdm import tqdm\n",
        "from accelerate import Accelerator\n",
        "from datetime import date\n",
        "\n",
        "import torch_geometric as tg\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "from IPython import display\n",
        "import matplotlib as mpl\n",
        "\n",
        "font = {'family' : 'DejaVu Sans',\n",
        "        'weight' : 'normal',\n",
        "        'size'   : 16}\n",
        "\n",
        "mpl.rc('font', **font)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8ojTeVLx2PO"
      },
      "source": [
        "Only need to do this step once, otherwise it's in the '/content/drive/My Drive/CS224W ML on Graphs/2025/Project/Mangrove-data' directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs6iVdASviMS",
        "outputId": "6555e820-1775-4d03-83f7-c89ed22df6fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/u/0/uc?id=192_gOXbEAhp4BSARobCsmJP2f98LsbGG\n",
            "From (redirected): https://drive.google.com/uc?id=192_gOXbEAhp4BSARobCsmJP2f98LsbGG&confirm=t&uuid=3a13dc0b-9839-41ba-846a-be520deb0115\n",
            "To: /content/drive/My Drive/CS224W ML on Graphs/2025/Project/Mangrove-data/data25.pkl\n",
            "100% 1.68G/1.68G [00:26<00:00, 63.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1FjyePBL8FNfTudRDMffHmamnBVq7EKAW\n",
            "To: /content/drive/MyDrive/CS224W ML on Graphs/2025/Project/Mangrove-data/construct_dict.pkl\n",
            "100% 852/852 [00:00<00:00, 4.33MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=17U1qqOvLj2J8TK0LTFUeMJcR26xLq5bQ\n",
            "To: /content/drive/MyDrive/CS224W ML on Graphs/2025/Project/Mangrove-data/model_best.pt\n",
            "100% 2.42M/2.42M [00:00<00:00, 16.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=12MCG8u6TYNSD-Y5exWe1yvu7rYUHQCyR\n",
            "To: /content/drive/MyDrive/CS224W ML on Graphs/2025/Project/Mangrove-data/result_dict.pkl\n",
            "100% 2.82M/2.82M [00:00<00:00, 20.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 'https://drive.google.com/u/0/uc?id=192_gOXbEAhp4BSARobCsmJP2f98LsbGG' # 25% of full data file, 1.56 GB\n",
        "!gdown 'https://drive.google.com/u/0/uc?id=1FjyePBL8FNfTudRDMffHmamnBVq7EKAW' # configuration file\n",
        "!gdown 'https://drive.google.com/u/0/uc?id=17U1qqOvLj2J8TK0LTFUeMJcR26xLq5bQ' # model\n",
        "!gdown 'https://drive.google.com/u/0/uc?id=12MCG8u6TYNSD-Y5exWe1yvu7rYUHQCyR' # results file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9gbKLl0wFHR"
      },
      "outputs": [],
      "source": [
        "data = pickle.load(open('data25.pkl', 'rb'))\n",
        "config = pickle.load(open('construct_dict.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Model"
      ],
      "metadata": {
        "id": "0ouIfP4TB-Mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\")\n",
        "print(\"number of graphs: \", len(data))\n",
        "print('==============================================================')\n",
        "idx = 4\n",
        "one_graph = data[idx]  # Get the first graph object.\n",
        "\n",
        "# Gather some statistics about the graph.\n",
        "print(\"graph at index: \", idx)\n",
        "print(one_graph)\n",
        "print(f'Number of nodes: {one_graph.num_nodes}')\n",
        "print(f'Number of edges: {one_graph.num_edges}')\n",
        "print(f'Average node degree: {(one_graph.num_edges) / one_graph.num_nodes:.2f}')\n",
        "print(f'Contains isolated nodes: {one_graph.has_isolated_nodes()}')\n",
        "print(f'Contains self-loops: {one_graph.has_self_loops()}')\n",
        "print(f'Is undirected: {one_graph.is_undirected()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25xRFiQ8BS5z",
        "outputId": "27ba3a4c-eac9-445d-cd6f-0dbdfa304e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "number of graphs:  27085\n",
            "==============================================================\n",
            "graph at index:  4\n",
            "Data(x=[10230, 43], edge_index=[2, 10229], edge_attr=[10229], y=[41])\n",
            "Number of nodes: 10230\n",
            "Number of edges: 10229\n",
            "Average node degree: 1.00\n",
            "Contains isolated nodes: False\n",
            "Contains self-loops: False\n",
            "Is undirected: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute the Laplacian\n",
        "You can choose which Laplacian you want:\n",
        "\n",
        "- Combinatorial: $L=D−A$\n",
        "- Symmetric normalized: $L_{sym} =I−D^{−1/2} A D^{−1/2}$\n",
        "- Random-walk normalized: $L_{rw} = I − D^{−1} A$"
      ],
      "metadata": {
        "id": "w7Z961HZCl7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import get_laplacian, to_dense_adj, to_scipy_sparse_matrix, to_undirected\n",
        "from scipy.sparse.linalg import eigsh  # sparse symmetric eigensolver\n",
        "\n",
        "def combinatorial_laplacian(data):\n",
        "    # data.edge_index is shape [2, num_edges]\n",
        "    edge_index = data.edge_index\n",
        "\n",
        "    # Returns edges and weights defining L = D - A\n",
        "    lap_edge_index, lap_edge_weight = get_laplacian(edge_index, normalization=None)\n",
        "\n",
        "    # Convert sparse representation to dense matrix\n",
        "    L = to_dense_adj(lap_edge_index, edge_attr=lap_edge_weight,\n",
        "                     max_num_nodes=data.num_nodes).squeeze(0)\n",
        "    return L\n",
        "\n",
        "\n",
        "def normalized_laplacian(data):\n",
        "    edge_index = data.edge_index\n",
        "\n",
        "    # Returns edges/weights for L_sym = I - D^{-1/2} A D^{-1/2}\n",
        "    lap_edge_index, lap_edge_weight = get_laplacian(edge_index, normalization='sym')\n",
        "\n",
        "    L = to_dense_adj(lap_edge_index, edge_attr=lap_edge_weight,\n",
        "                     max_num_nodes=data.num_nodes).squeeze(0)\n",
        "    return L\n",
        "\n",
        "\n",
        "def random_walk_laplacian(data):\n",
        "    edge_index = data.edge_index\n",
        "\n",
        "    # L_rw = I - D^{-1} A\n",
        "    lap_edge_index, lap_edge_weight = get_laplacian(edge_index, normalization='rw')\n",
        "\n",
        "    L = to_dense_adj(lap_edge_index, edge_attr=lap_edge_weight,\n",
        "                     max_num_nodes=data.num_nodes).squeeze(0)\n",
        "    return L\n",
        "\n",
        "\n",
        "def laplacian_positional_encoding(data, k, normalization='sym'):\n",
        "    \"\"\"\n",
        "    Compute top-k non-trivial Laplacian eigenvectors for a PyG Data graph.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data          : torch_geometric.data.Data Graph\n",
        "                    with data.edge_index and data.num_nodes.\n",
        "    k             : int Number of *non-trivial* eigenvectors\n",
        "                    to return (skips the constant one).\n",
        "    normalization : {'sym', 'rw', None}, optional\n",
        "          - 'sym' : symmetric normalized Laplacian  L = I - D^{-1/2} A D^{-1/2}\n",
        "          - 'rw'  : random-walk Laplacian           L = I - D^{-1} A\n",
        "          - None  : combinatorial Laplacian         L = D - A\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    eigvecs : torch.Tensor, shape [num_nodes, k]\n",
        "              The k Laplacian eigenvectors (columns), as float32.\n",
        "    eigvals : torch.Tensor, shape [k]\n",
        "              Corresponding eigenvalues (ascending, skipping the trivial 0).\n",
        "    \"\"\"\n",
        "    num_nodes = data.num_nodes\n",
        "    edge_index = data.edge_index\n",
        "\n",
        "    # 1) Build Laplacian in sparse form\n",
        "    lap_edge_index, lap_edge_weight = get_laplacian(\n",
        "        edge_index,\n",
        "        normalization=normalization,\n",
        "        num_nodes=num_nodes\n",
        "    )\n",
        "\n",
        "    L = to_scipy_sparse_matrix(lap_edge_index, lap_edge_weight, num_nodes=num_nodes)\n",
        "\n",
        "    # 2) Compute smallest (k+1) eigenpairs: include trivial 0, then skip it\n",
        "    #    (for connected graphs; if graph is disconnected you may want more)\n",
        "    evals, evecs = eigsh(L, k=k+1, which='SM')  # SM = smallest magnitude\n",
        "\n",
        "    # 3) Sort just in case and drop the first (trivial) eigenvector\n",
        "    idx = evals.argsort()\n",
        "    evals, evecs = evals[idx], evecs[:, idx]\n",
        "\n",
        "    # drop the first eigenpair (corresponding to eigenvalue ~0)\n",
        "    evals_nontriv = evals[1:k+1]\n",
        "    evecs_nontriv = evecs[:, 1:k+1]\n",
        "\n",
        "    eigvecs = torch.from_numpy(evecs_nontriv).float()\n",
        "    eigvals = torch.from_numpy(evals_nontriv).float()\n",
        "    return eigvecs, eigvals\n",
        "\n",
        "\n",
        "def make_undirected(data):\n",
        "    data = data.clone()\n",
        "    data.edge_index = to_undirected(data.edge_index, num_nodes=data.num_nodes)\n",
        "    return data"
      ],
      "metadata": {
        "id": "0mMwBfiYBS2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L = combinatorial_laplacian(one_graph)\n",
        "print(L.shape)\n",
        "Lambda = laplacian_positional_encoding(one_graph, 10, normalization=None)\n",
        "print(Lambda[0].shape)\n",
        "print(Lambda[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikOHvVQWBSlf",
        "outputId": "12c1ab25-72e2-4379-b2de-8b0f70e7aebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10230, 10230])\n",
            "torch.Size([10230, 10])\n",
            "tensor([0.0141, 0.0166, 0.0182, 0.0183, 0.0212, 0.0246, 0.0272, 0.0562, 0.0599,\n",
            "        0.0641])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confirm the computed eigenvectors satisfy the eigenvector equation. Note we have to convert the graphs to undirected to get a symmetric Laplacian."
      ],
      "metadata": {
        "id": "q3hNrNykSUaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "undirected_graph = make_undirected(one_graph)\n",
        "\n",
        "L = combinatorial_laplacian(undirected_graph)\n",
        "eigvecs, eigvals = laplacian_positional_encoding(undirected_graph, 10, normalization=None)\n",
        "\n",
        "i = 2\n",
        "v = eigvecs[:, i]\n",
        "lam = eigvals[i]\n",
        "\n",
        "Lv = L @ v\n",
        "lamv = lam * v\n",
        "\n",
        "residual = Lv - lamv\n",
        "err = residual.norm().item()\n",
        "rel_err = err / (lamv.norm().item() + 1e-12)\n",
        "\n",
        "print(\"‖Lv - λv‖ =\", err)\n",
        "print(\"relative error =\", rel_err)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNcklc9dBShT",
        "outputId": "da772e09-dbe0-410d-8142-4999bdcc272b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‖Lv - λv‖ = 3.320720134070143e-05\n",
            "relative error = 0.5093721702625378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute a new dataset with augmented positional information"
      ],
      "metadata": {
        "id": "Y3zaDmq8TFfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data, Dataset\n",
        "\n",
        "def augment_with_lappe(data: Data, k: int, normalization=None) -> Data:\n",
        "    \"\"\"\n",
        "    Return a clone of `data` where node features are augmented with\n",
        "    k-dimensional Laplacian positional encodings.\n",
        "    \"\"\"\n",
        "    # Work on an undirected version for symmetric Laplacian\n",
        "    data_u = make_undirected(data)\n",
        "\n",
        "    # Compute eigenvectors on the undirected graph\n",
        "    eigvecs, eigvals = laplacian_positional_encoding(\n",
        "        data_u, k=k, normalization=normalization\n",
        "    )  # eigvecs: [N, k_eff]\n",
        "\n",
        "    # If we requested k but got fewer (small graph), we can pad or just concat as-is.\n",
        "    # Here we just concat as-is; dimensions will be <= k.\n",
        "    pe = eigvecs  # [num_nodes, k_eff]\n",
        "\n",
        "    aug_data = data.clone()\n",
        "\n",
        "    if aug_data.x is None:\n",
        "        aug_data.x = pe\n",
        "    else:\n",
        "        # Concatenate along feature dimension\n",
        "        aug_data.x = torch.cat([aug_data.x, pe], dim=-1)\n",
        "\n",
        "    # Optionally store eigenvalues too if you want them later:\n",
        "    aug_data.lap_eigvals = eigvals\n",
        "\n",
        "    return aug_data\n",
        "\n",
        "\n",
        "def augment_dataset_with_lappe(dataset: Dataset, k: int, normalization=None):\n",
        "    \"\"\"\n",
        "    Iterate through a PyG Dataset, augment each graph with Laplacian PEs,\n",
        "    and return a list of augmented Data objects.\n",
        "    \"\"\"\n",
        "    augmented_graphs = []\n",
        "\n",
        "    min_nodes = 2*k\n",
        "    if k > 10:\n",
        "      min_nodes = 4*k\n",
        "\n",
        "    for data in tqdm(dataset, desc=\"Augmenting graphs with Laplacian PEs\"):\n",
        "        if data.num_nodes > 5000 or data.num_nodes <= min_nodes:\n",
        "            continue\n",
        "        aug_data = augment_with_lappe(data, k=k, normalization=normalization)\n",
        "        augmented_graphs.append(aug_data)\n",
        "\n",
        "    return augmented_graphs\n",
        "    '''\n",
        "    for i, data in enumerate(dataset):\n",
        "        if data.num_nodes > 5000:\n",
        "            continue\n",
        "        print(f\"Processing graph {i+1}/{len(dataset)} ...\")\n",
        "        aug_data = augment_with_lappe(data, k=k, normalization=normalization)\n",
        "        augmented_graphs.append(aug_data)\n",
        "    return augmented_graphs\n",
        "    '''\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "la0HUt1TFA-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9c7773a",
        "outputId": "26619520-0fa3-4f18-8e2b-565506af2169"
      },
      "source": [
        "import pickle\n",
        "\n",
        "ks = [1, 2, 3, 5, 11, 20]  # You can adjust this value for the number of Laplacian PE dimensions\n",
        "normalization = None  # Choose 'sym', 'rw', or None for combinatorial Laplacian\n",
        "\n",
        "for k in ks:\n",
        "  # Call augment_dataset_with_lappe to process the dataset\n",
        "  augmented_graphs = augment_dataset_with_lappe(data, k=k, normalization=normalization)\n",
        "\n",
        "  # Define the output path for the pickle file\n",
        "  output_path = f\"dataset_with_lapPE{k}.pkl\"\n",
        "\n",
        "  # Save the augmented dataset as a pickle file\n",
        "  with open(output_path, \"wb\") as f:\n",
        "      pickle.dump(augmented_graphs, f)\n",
        "\n",
        "  print(f\"Saved augmented dataset with Laplacian PEs to: {output_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting graphs with Laplacian PEs: 100%|██████████| 27085/27085 [49:43<00:00,  9.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved augmented dataset with Laplacian PEs to: dataset_with_lapPE1.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting graphs with Laplacian PEs: 100%|██████████| 27085/27085 [38:47<00:00, 11.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved augmented dataset with Laplacian PEs to: dataset_with_lapPE2.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting graphs with Laplacian PEs: 100%|██████████| 27085/27085 [36:20<00:00, 12.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved augmented dataset with Laplacian PEs to: dataset_with_lapPE3.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting graphs with Laplacian PEs: 100%|██████████| 27085/27085 [30:42<00:00, 14.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved augmented dataset with Laplacian PEs to: dataset_with_lapPE5.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting graphs with Laplacian PEs: 100%|██████████| 27085/27085 [26:37<00:00, 16.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved augmented dataset with Laplacian PEs to: dataset_with_lapPE11.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting graphs with Laplacian PEs: 100%|██████████| 27085/27085 [22:02<00:00, 20.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved augmented dataset with Laplacian PEs to: dataset_with_lapPE20.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\")\n",
        "print(\"number of graphs: \", len(augmented_graphs))\n",
        "print('==============================================================')\n",
        "idx = 4\n",
        "one_graph = augmented_graphs[idx]  # Get the first graph object.\n",
        "\n",
        "# Gather some statistics about the graph.\n",
        "print(\"graph at index: \", idx)\n",
        "print(one_graph)\n",
        "print(f'Number of nodes: {one_graph.num_nodes}')\n",
        "print(f'Number of edges: {one_graph.num_edges}')\n",
        "print(f'Average node degree: {(one_graph.num_edges) / one_graph.num_nodes:.2f}')\n",
        "print(f'Contains isolated nodes: {one_graph.has_isolated_nodes()}')\n",
        "print(f'Contains self-loops: {one_graph.has_self_loops()}')\n",
        "print(f'Is undirected: {one_graph.is_undirected()}')"
      ],
      "metadata": {
        "id": "KKO8i9PrFA4m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN8CCZgVlguRYPDzCnMQw/m",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}